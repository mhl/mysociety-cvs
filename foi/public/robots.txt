# See http://www.robotstxt.org/wc/norobots.html for documentation on how to use the robots.txt file

# Mainly to reduce server load from bots, we block pages which are actions, and
# searches. We also block /feed/, as RSS readers (rightly, I think) don't seem
# to check robots.txt.

User-agent: *
Disallow: /annotate/
Disallow: /new/
Disallow: /search/
Disallow: /similar/
Disallow: /track/
Disallow: /upload/
Disallow: /user/contact/
Disallow: /feed/
Disallow: /signin

